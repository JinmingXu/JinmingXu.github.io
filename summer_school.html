<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>ZJU-CSE Summer School 2021</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">AboutMe</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="biography.html">Biography</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="projects.html">Projects</a></div>
<div class="menu-category">Education</div>
<div class="menu-item"><a href="summer_school.html" class="current">Summer&nbsp;School</a></div>
<div class="menu-category">Miscellaneous</div>
<div class="menu-item"><a href="usefulinks.html">Useful&nbsp;Links</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>ZJU-CSE Summer School 2021</h1>
</div>
<h2>Introduction to the summer school</h2>
<div class="infoblock">
<div class="blockcontent">
<p>The summer school covers several recent advances in the topic of <b>distributed control, optimization and learning</b>. The main object of the course is to present in an accessible way (lectures, tutorial/seminars) to graduate students some advanced control and optimization methods for large-scale systems that arise in modern control engineering and data science. The content of the course covers basics for convex optimization, first-order optimization methods (e.g., gradient method, stochastic method, accelerated gradient methods and primal-dual methods), decomposition and splitting methods (e.g., dual decomposition, monotone operators and operator splitting, ADMM), as well as recent developed parallel and distributed algorithms. Besides, several tutorial/seminars from leading research scholars will be provided to introduce some frontier advanced topics in distributed control, optimization and learning. To enhance the learning outcome of students, new online learning models, such as SPOC, will be likely employed to promote self-learning and diversity of learning processes, along with a bunch of concrete examples including smart grid, sensor networks and machine learning for the sake of enriching the content of the course. After completing this course, the students are expected to be able to apply the control and optimization techniques learned from this course to large-scale cyber-physical systems as well as other related research areas.</p>
</div></div>
<h2>Course Content</h2>
<p><b>Lectures</b></p>
<ul>
<li><p>Day 1. <b>Introduction to the course</b></p>
<ul>
<li><p><b>Lecture I</b>: Background • Convex Set • (Non)-Convex Function • Smoothness • Strong Convexity • Strong Duality • Slater Condition • KKT(<b><a href="https://www.bilibili.com/video/BV1Ng411L7UA">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Lecture_1.pdf">Slides</a></b>)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Day 2. <b>Convex Optimization</b></p>
<ul>
<li><p><b>Lecture II</b>: (Unconstrained) Convex Optimization Problem • Gradient Method • Convergence Property and Analysis(<b><a href="https://www.bilibili.com/video/BV1Af4y1N7DR">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Lecture_2.pdf">Slides</a></b>)</p>
</li>
<li><p><b>Lecture III</b>: Graph Basics • Weight Matrix • Average Consensus • pf theorem(<b><a href="https://www.bilibili.com/video/BV1fQ4y1Y7je">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Lecture_3.pdf">Slides</a></b>)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Day 3. <b>Distributed Convex Optimization</b></p>
<ul>
<li><p><b>lecture IV</b>: (Par I): Finite-Sum Problem • Distributed Optimization • Distributed Primal Algorithms: DGD, Gradient Tracking, Push-Pull/SONATA(<b><a href="https://www.bilibili.com/video/BV1Gy4y1G7Fq">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Lecture_4.pdf">Slides</a></b>)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Day 4. <b>Distributed Stochastic Optimization</b></p>
<ul>
<li><p><b>Lecture V</b>: Stochastic Gradient Methods • Convergence Analysis • Variance Reduced Methods: SAG, SAGA, SVRG(<b><a href="https://www.bilibili.com/video/BV1YU4y1j7Uz">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Lecture_5.pdf">Slides</a></b>) </p>
</li>
<li><p><b>Lecture VI</b>: Distributed Stochastic Optimization • Momentum acceleration • Decentralized Deep Learning(<b><a href="https://www.bilibili.com/video/BV1mQ4y1Y7Pe">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Lecture_6_I.pdf">Slides_1</a>, <a href="http://JinmingXu.github.io/Lecture_6_II.pdf">Slides_2</a>, <a href="http://JinmingXu.github.io/Lecture_6_III.pdf">Slides_3</a></b>)</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Day 5. <b>Advanced Topics in (Distributed) Optimization</b></p>
<ul>
<li><p><b>Lecture VIII</b>: Composite Optimization • Proximal/Projected Gradient Methods •  Proximal Point Method • Monotone Operators • ADMM • Primal-dual formulation • Distributed Primal-Dual Methods(<b><a href="https://www.bilibili.com/video/BV1aL411b7Td">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Lecture_7.pdf">Slides</a></b>)</p>
</li>
<li><p><b>Lecture IX</b>: Accelerated Coordinate descent Methods • Accelerated Stochastic Primal-Dual Methods • Accelerated Gradient Tracking • Acceleration for Escaping saddle point(<b><a href="https://www.bilibili.com/video/BV1eQ4y1Y7A3">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Lecture_8.pdf">Slides</a></b>)</p>
</li>
</ul>

</li>
</ul>
<p><b>Tutorial/Seminars(tentative)</b></p>
<ul>
<li><p><font color=blue size=+0.8><b> Day 1. Distributed Non-Convex Optimization</b></font> <br /></p>
</li>
</ul>
<table class="imgtable"><tr><td>
<a href="https://www1.se.cuhk.edu.hk/~htwai/"><img src="m2.jpeg" alt="Not Available" width="WIDTHpx" height="180px" /></a>&nbsp;</td>
<td align="left"><p><b>Title(T/S II):</b> Decentralized learning in the nonconvex world: Recent results<br />
<b>Speaker:</b> Prof Hoi To Wai, Chinese University of Hong Kong<br />
<b>Date/Time:</b> August 9, 2021, 10:00am-12:00pm, China Time (<a href="https://dateful.com/eventlink/3166995376">Check your local time here</a>)<br />
<b>Abstract:</b> Decentralized learning has become a critical enabler of the massively connected world that many people envision. In this talk, we discuss four key elements of scalable decentralized optimization and control: optimization problems, data, communication, and computation. We describe how these elements should work together in an effective and coherent manner. We review recent techniques developed for optimizing nonconvex models (i.e., problem classes) that process batch/streaming data (data types) across networks in a decentralized manner (communication and computation paradigm). We describe the intuitions and connections behind a core set of popular decentralized algorithms, emphasizing how to balance computation and communication costs. Practical issues and future research directions will also be discussed.<br />
<b>Speaker Homepage:</b> <a href="https://www1.se.cuhk.edu.hk/~htwai/">https://www1.se.cuhk.edu.hk/~htwai/</a><br />
<b><a href="https://www.bilibili.com/video/BV1ZQ4y1h7xX">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Seminar_1.pdf">Slides</a></b><br /></p>
</td></tr></table>
<p><br /></p>
<table class="imgtable"><tr><td>
<a href="https://www.eecs.tufts.edu/~khan/"><img src="m1.jpeg" alt="Not Available" width="WIDTHpx" height="180px" /></a>&nbsp;</td>
<td align="left"><p><b>Title(T/S I):</b>Distributed stochastic non-convex optimization: Optimal regimes and tradeoffs<br />
<b>Speaker:</b> Prof Usman Khan, Tufts University<br />
<b>Date/Time:</b> August 9, 2021, 8:30pm-10:00pm, China Time (<a href="https://dateful.com/eventlink/4580562596">Check your local time here</a>)<br />
<b>Abstract:</b> In many emerging applications, it is of paramount interest to learn hidden parameters from data. For example, self-driving cars may use onboard cameras to identify pedestrians, highway lanes, or traffic signs in various light and weather conditions. Problems such as these can be framed as classification, regression, or risk minimization in general, at the heart of which lies stochastic optimization and machine learning. In many practical scenarios, distributed and decentralized learning methods are preferable as they benefit from a divide-and-conquer approach towards data at the expense of local (short-range) communication. In this talk, I will present our recent work that develops a novel algorithmic framework to address various aspects of decentralized stochastic first-order optimization methods for non-convex problems. A major focus will be to characterize regimes where decentralized solutions outperform their centralized counterparts and lead to optimal convergence guarantees. Moreover, I will characterize certain desirable attributes of decentralized methods in the context of linear speedup and networkindependent convergence rates. Throughout the talk, I will demonstrate such key aspects of the proposed methods with the help of provable theoretical results and numerical experiments on real data.<br />
<b>Speaker Homepage:</b> <a href="https://www.eecs.tufts.edu/~khan/">https://www.eecs.tufts.edu/~khan/</a><br />
<b><a href="https://www.bilibili.com/video/BV18L41147e1">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Seminar_2.pdf">Slides</a></b><br /></p>
</td></tr></table>
<ul>
<li><p><font color=blue size=+0.8><b> Day 2. Distributed Convex Optimization</b></font> <br /></p>
</li>
</ul>
<table class="imgtable"><tr><td>
<a href="https://cauribe.rice.edu/"><img src="m3.jpeg" alt="Not Available" width="WIDTHpx" height="180px" /></a>&nbsp;</td>
<td align="left"><p><b>Title(T/S III):</b> Towards Scalable Algorithms for Distributed Optimization and Learning<br />
<b>Speaker:</b> Prof. Cesar Uribe, Rice University<br />
<b>Date/Time:</b> August 10, 2021, 8:30am-10:00am, China Time (<a href="https://dateful.com/eventlink/1191167358">Check your local time here</a>)<br />
<b>Abstract:</b> Increasing amounts of data generated by modern complex systems such as the energy grid, social media platforms, sensor networks, and cloud-based services call for attention to distributed data processing, in particular, for the design of scalable algorithms that take into account storage and communication constraints and help to make coordinated decisions. In this talk, we present recently proposed distributed algorithms with optimal convergence rates for optimization problems over networks, where data is stored distributedly. We focus on scalable algorithms and show they can achieve the same rates as their centralized counterparts, with an additional cost related to the structure of the network. We provide application examples to distributed inference and learning, and computational optimal transport.<br />
<b>Speaker Homepage:</b> <a href="https://cauribe.rice.edu/">https://cauribe.rice.edu/</a><br />
<b><a href="https://www.bilibili.com/video/BV1iL4y1Y7VB">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Seminar_3.pdf">Slides</a></b><br /></p>
</td></tr></table>
<p><br /></p>
<table class="imgtable"><tr><td>
<a href="https://angelia.engineering.asu.edu/"><img src="m4.jpeg" alt="Not Available" width="WIDTHpx" height="180px" /></a>&nbsp;</td>
<td align="left"><p><b>Title(T/S IV):</b> Distributed Optimization over Networks<br />
<b>Speaker:</b> Prof Angelia Nedich, Arizona State University<br />
<b>Date/Time:</b> August 10, 2021, 10:30am-12:00pm, China Time (<a href="https://dateful.com/eventlink/3075169688">Check your local time here</a>)<br />
<b>Abstract:</b> TBD<br />
<br />
<br />
<br />
<br />
<br />
<br />
<b>Speaker Homepage:</b> <a href="https://angelia.engineering.asu.edu/">https://angelia.engineering.asu.edu/</a><br /></p>
</td></tr></table>
<ul>
<li><p><font color=blue size=+0.8><b> Day 3. Distributed Algorithms for High-dimensional Learning</b></font> <br /></p>
</li>
</ul>
<table class="imgtable"><tr><td>
<a href="https://engineering.purdue.edu/~gscutari/"><img src="m5.jpeg" alt="Not Available" width="WIDTHpx" height="180px" /></a>&nbsp;</td>
<td align="left"><p><b>Title(T/S V):</b> Bringing Statistical Thinking in Distributed Optimization. Vignettes from statistical inference over Networks (Part I, Part II)<br />
<b>Speaker:</b> Prof Gesualdo Scutari, Purdue University<br />
<b>Date/Time:</b> August 11, 2021, 8:30am-12:00pm, China Time (<a href="https://dateful.com/eventlink/2793218183">Check your local time here</a>)<br />
<b>Abstract:</b> There is growing interest in solving large-scale statistical machine learning problems over decentralized networks, where data are distributed across the nodes of the network and no centralized coordination is present (we termed these systems “meshed” networks). Modern massive datasets create a fundamental problem at the intersection of the computational and statistical sciences: how to provide guarantees on the quality of statistical inference given bounds on computational resources, such as time and communication efforts. While statistical-computation tradeoffs have been largely explored in the centralized setting, our understanding over meshed networks is limited: (i) distributed schemes, designed and performing well in the classical low-dimensional regime, can break down in the high-dimensional case; and (ii) existing convergence studies may fail to predict algorithmic behaviors; some are in fact confuted by experiments. This is mainly due to the fact that the majority of distributed algorithms over meshed networks have been designed and studied only from the optimization perspective, lacking the statistical dimension. Throughout some vignettes from low- and high-dimensional statistical inference, this talk goes over some designs and new analyses aiming at bringing statistical thinking in distributed optimization.<br />
<b>Speaker Homepage:</b> <a href="https://engineering.purdue.edu/~gscutari/">https://engineering.purdue.edu/~gscutari/</a><br />
<b><a href="https://www.bilibili.com/video/BV1jL4y1h7zz?spm_id_from=333.999.0.0">Video Link(BiliBili)</a></b><br /></p>
</td></tr></table>
<p><br /></p>
<ul>
<li><p><font color=blue size=+0.8><b> Day 4. Distributed Control and Intelligent Autonomous Systems</b></font> <br /></p>
</li>
</ul>
<table class="imgtable"><tr><td>
<a href="https://doe.carleton.ca/shichao-liu"><img src="m6.jpeg" alt="Not Available" width="WIDTHpx" height="180px" /></a>&nbsp;</td>
<td align="left"><p><b>Title(T/S VI):</b>  Distributed Load Frequency Control in Smart Grids<br />
<b>Speaker:</b> Prof Shichao Liu, Carleton University<br />
<b>Date/Time:</b> August 12, 2021, 8:30am-10:00am, China Time (<a href="https://dateful.com/eventlink/2807365084">Check your local time here</a>)<br />
<b>Abstract:</b> In a multi-area smart grid, the load frequency control is used to sustain the frequency of each control area and tie-line power at scheduled values through modifying power set points in case disturbances happen. For the cost-effective operation of the LFC, there are many challenges to be addressed such as controllers with limited energy resources and tremendous information exchanged among a large number of areas in the smart grid. In this talk, we firstly introduce smart grid control and communication structures. Then, the basics of load frequemcy control are covered briefly. At the end, we present distributed control and event-triggering schedule co-design schemes to tackle these challenges. These distributed control and scheduling coordination approaches can reduce the amount of needed information transmissions while not sacrificing the system dynamic performance.<br />
<b>Speaker Homepage:</b> <a href="https://doe.carleton.ca/shichao-liu">https://doe.carleton.ca/shichao-liu</a><br />
<b><a href="https://www.bilibili.com/video/BV15y4y1G7Qa">Video Link(BiliBili)</a>, <a href="http://JinmingXu.github.io/Seminar_5.pdf">Slides</a></b><br /></p>
</td></tr></table>
<p><br /></p>
<table class="imgtable"><tr><td>
<a href="https://www3.ntu.edu.sg/home/elhxie/index.html"><img src="m7.jpeg" alt="Not Available" width="WIDTHpx" height="180px" /></a>&nbsp;</td>
<td align="left"><p><b>Title(T/S VII):</b> Smart Sensing and Localization<br />
<b>Speaker:</b> Prof Lihua Xie, Nanyang Technological University<br />
<b>Date/Time:</b> August 12, 2021, 10:30am-12:00pm, China Time (<a href="https://dateful.com/eventlink/2711855753">Check your local time here</a>)<br />
<b>Abstract:</b> Sensing and localization are essential for IoT and intelligent unmanned systems. GPS has been widely used for positioning and navigation. However, in indoor and many outdoor environments such as urban canon, forest, tunnel, GPS may not be available or unreliable. Hence, there has been a lot of interest in developing technologies and algorithms for localization in such environments. In this talk, we shall discuss several sensing and localization systems and algorithms we have developed over the past few years including WiFi based indoor positioning and human activity recognition, UWB based localization, and vision-inertial-range sensor fusion for localization and mapping.  Their applications in smart building/home, elderly care, UAV based structure inspection and AGV for logistics will be presented, and challenges and future research directions will be highlighted.<br />  
<b>Speaker Homepage:</b> <a href="https://www3.ntu.edu.sg/home/elhxie/index.html">https://www3.ntu.edu.sg/home/elhxie/index.html</a><br /></p>
</td></tr></table>
<ul>
<li><p><font color=blue size=+0.8><b> Day 5. Group Sharing and Discussion</b></font> <br /></p>
</li>
</ul>
<h2>Way of Teaching</h2>
<ul>
<li><p><b>Language</b>: Bilingual (English + Chinese)</p>
</li>
<li><p><b>Course Form</b>: Lectures (Basics) + Tutorials/Seminars (Advanced Topics)</p>
</li>
<li><p><b>Manner</b>: Online (key concepts; Sketch of proofs) + Offline (Mathematical derivation)</p>
</li>
</ul>
<h2>Invited  speakers</h2>
<div class="infoblock">
<div class="blockcontent">
<ul>
<li><p><a href="https://engineering.purdue.edu/~gscutari/">Prof Gesualdo Scutari, Purdue University</a></p>
</li>
<li><p><a href="https://ysunac.github.io/">Prof Ying Sun, Pennsylvania State University</a></p>
</li>
<li><p><a href="https://www3.ntu.edu.sg/home/elhxie/index.html">Prof Lihua Xie, Nanyang Technological University</a></p>
</li>
<li><p><a href="https://angelia.engineering.asu.edu/">Prof Angelia Nedich, Arizona State University</a></p>
</li>
<li><p><a href="https://www.eecs.tufts.edu/~khan/">Prof Usman Khan, Tufts University</a></p>
</li>
<li><p><a href="https://www1.se.cuhk.edu.hk/~htwai/">Prof Hoi To Wai, Chinese University of Hong Kong</a></p>
</li>
<li><p><a href="https://cauribe.rice.edu/">Prof Cesar Uribe, Rice University</a></p>
</li>
<li><p><a href="https://doe.carleton.ca/shichao-liu">Prof Shichao Liu, Carleton University</a></p>
</li>
<li><p><a href="https://person.zju.edu.cn/en/wmeng">Prof Wenchao Meng, Zhejiang University</a></p>
</li>
<li><p><a href="https://person.zju.edu.cn/en/czhao">Prof Chengcheng Zhao, Zhejiang University</a></p>
</li>
<li><p><a href="https://scholar.google.com/citations?user=aMnHLz4AAAAJ&amp;hl=en">Dr. Kun Yuan, Damo Academy</a></p>
</li>
<li><p><a href="https://ai.nankai.edu.cn/info/1102/4244.htm">Prof Huan Li, Nankai University</a></p>
</li>
</ul>
</div></div>
<h2>Time Schedule</h2>
<p><b>Week One (Aug 02 - Aug 06)</b></p>
<table id="Lectures">
<tr class="r1"><td class="c1">Time  </td><td class="c2"> Monday (Aug 02)  </td><td class="c3">  Tuesday(Aug 03)  </td><td class="c4">  Wednesday(Aug 04)  </td><td class="c5">  Thursday(Aug 05)  </td><td class="c6">  Friday(Aug 06) </td></tr>
<tr class="r2"><td class="c1">8.30 am - 12.00 pm<br /> (GMT+8)  </td><td class="c2"> Lecture I<br /> <b>Introduction to the course</b><br /> (Chinese)<br /><br /> Speaker<br /> Jinming Xu, ZJU<br />（Yuquan Campus）<br /> <br /> <b>Tencent Meeting ID:</b><br /> 752 593 984 </td><td class="c3">  Lecture II<br /> <b>Convex Optimization</b><br /> (English)<br /> <br /> Speaker<br /> Ying Sun, PSU<br />（online）<br /> <br /> <b>Tencent Meeting ID:</b><br /> 755 843 514  </td><td class="c4">  Lecture IV<br /> <b>Distributed Convex Optimization</b><br /> (English)<br /> <br /> Speaker<br /> Ying Sun, PSU<br />（online）<br /> <br /> <b>Tencent Meeting ID:</b><br /> 642 952 965 </td><td class="c5">  Lecture  V<br /> <b>Stochastic Optimization</b><br /> (English)<br /> <br /> Speaker<br /> Ying Sun, PSU<br />（online）<br /> <br /> <b>Tencent Meeting ID:</b><br /> 708 668 998 </td><td class="c6">  Lecture VIII<br /> <b>Advanced Topics(Operator Splitting, ADMM)</b><br /> (Chinese)<br /> <br /> Speaker<br /> Jinming Xu, ZJU<br />（Yuquan Campus）<br /> <br /> <b>Tencent Meeting ID:</b><br /> 479 145 622 </td></tr>
<tr class="r4"><td class="c1">12.00 pm - 2.30 pm<br /> (GMT+8)  </td><td class="c2"> Lunch Break </td><td class="c3">  Lunch Break  </td><td class="c4">  Lunch Break  </td><td class="c5">  Lunch Break  </td><td class="c6">  Lunch Break  </td></tr>
<tr class="r5"><td class="c1">2.30 pm - 5.30 pm<br /> (GMT+8) </td><td class="c2"> <b>Lab Tour</b><br /> <br /> Shining Gao/Anjun Chen<br /> (Yuquan Campus)</td><td class="c3"> Lecture III<br /> <b>Graph Basics and Consensus</b><br /> (Chinese) <br /><br /> Speaker<br /> Prof Chengcheng Zhao, ZJU<br />（Yuquan Campus）<br /> <br /> <b>Tencent Meeting ID:</b><br /> 624 997 500  </td><td class="c4">  Research & Discussion </td><td class="c5"> Lecture VI<br /> <b>Distributed Stochastic Optimization</b><br /> <br /> Speaker<br /> Kun Yuan, Damo Academy<br /> (Yuquan Campus) <br /> <br /> <b>Tencent Meeting ID:</b><br /> 202 219 103 </td><td class="c6"> Lecture IX<br /> <b>Advanced Topics(Acceleration)</b><br /> (Chinese) <br /> <br /> Speaker<br /> Huan Li, NKU<br />(Yuquan Campus) <br /> <br /> <b>Tencent Meeting ID:</b><br /> 962 195 511 </td></tr>
<tr class="r6"><td class="c1">
</td></tr></table>
<p><br />
<b>Week Two (Aug 09 - Aug 13)</b></p>
<table id="TABLENAME">
<tr class="r1"><td class="c1">Time  </td><td class="c2"> Monday (Aug 09)  </td><td class="c3">  Tuesday(Aug 10)  </td><td class="c4">  Wednesday(Aug 11)  </td><td class="c5">  Thursday(Aug 12)  </td><td class="c6">  Friday(Aug 13) </td></tr>
<tr class="r2"><td class="c1">8.30 am - 12.00 pm<br /> (GMT+8)  </td><td class="c2"> T/S I<br /> Prof. Usman Khan, Tufts Univ<br /> <font color=red size=+1.2><b> (8.30pm-10.00pm) </b></font> <br /> <b>Zoom Meeting ID:</b><br />  499 292 8524<br />  <br /> <br /> T/S II<br /> Prof. Hoi To Wai, CUHK<br /> (10.00am-12.00pm) <br /> <br /> <b>Zoom Meeting ID:</b><br />  499 292 8524<br />  </td><td class="c3"> T/S III<br /> Prof Cesar Uribe, Rice<br /> (8.30am-10.00am) <br /> <br /> T/S IV<br /> Prof Angelia Nedich, ASU <br /> (10.30am-12.00pm) <br /> <br /> <b>Zoom Meeting ID:</b><br />  499 292 8524<br />  </td><td class="c4"> T/S V<br /> Part I/Part II<br /><br /> Prof Gesualdo Scutari, Purdue <br /> <br /> <b>Zoom Meeting ID:</b><br />  499 292 8524<br /> </td><td class="c5"> T/S VI<br /> Prof Shichao liu, Carleton<br /> (8.30am-10.00am)<br /> <br /> T/S VII<br /> Prof Xie Lihua, NTU <br /> (10.30am-12.00pm) <br /> <br /> <b>Zoom Meeting ID:</b><br />  499 292 8524<br /> </td><td class="c6"> Group Sharing & Discussion </td></tr>
<tr class="r3"><td class="c1">12.00 pm - 2.30 pm<br /> (GMT+8)  </td><td class="c2"> Lunch Break </td><td class="c3">  Lunch Break  </td><td class="c4">  Lunch Break  </td><td class="c5">  Lunch Break  </td><td class="c6">  Lunch Break  </td></tr>
<tr class="r4"><td class="c1">2.30 pm - 5.30 pm<br /> （GMT+8） </td><td class="c2">  Lecture VII<br /> <b>Distributed Control</b><br /> <br /> Speaker<br /> Prof Meng Wenchao, ZJU<br />（Yuquan Campus）<br /> <br /> <b>Tencent Meeting ID:</b><br /> 751 993 484 </td><td class="c3">  Research & Discussion </td><td class="c4">  Research & Discussion </td><td class="c5"> Research & Discussion  </td><td class="c6">   </td></tr>
<tr class="r5"><td class="c1">
</td></tr></table>
<h2>Registration and Deadlines</h2>
<p><b>Registration</b>:<br />
Welcome to register (free) this event via the following link<br />
<a href="https://jinshuju.net/f/KEOdJK">https://jinshuju.net/f/KEOdJK</a><br />
<br />
<b>Deadlines</b>:<br />
Pre-registration: 28 July 2021;<br />
Notification: 30 July 2021.</p>
<h2>Organizers and Contact</h2>
<p>This event is organized by <a href="https://jinmingxu.github.io/">Jinming Xu</a> (ZJU), <a href="https://person.zju.edu.cn/en/wmeng">Wenchao Meng</a> (ZJU), <a href="https://person.zju.edu.cn/en/czhao">Chengcheng Zhao</a> (ZJU) and <a href="https://ysunac.github.io/">Ying Sun</a> (PSU) with the advisory board member <a href="https://scholar.google.com/citations?user=zK9tvo8AAAAJ&amp;hl=zh-CN">Jiming Chen</a> (ZJU), <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=0Z1uk7YAAAAJ">Peng Cheng</a> (ZJU) and <a href="https://engineering.purdue.edu/~gscutari/">Gesualdo Scutari</a> (Purdue). For inquiries, please write to <a href="mailto:jimmyxu@zju.edu.cn">jimmyxu AT zju.edu.cn</a>.</p>
<div id="footer">
<div id="footer-text">
Page generated 2021-09-06 17:25:33 CST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
